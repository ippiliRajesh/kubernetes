# spark-config.yaml
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-app
spec:
  type: Scala  # Application type (Scala, Java, PySpark, etc.)
  mode: cluster  # Cluster mode or client mode
  image: your-spark-image  # Spark Docker image
  mainClass: org.apache.spark.examples.SparkPi  # Main class for your application
  sparkVersion: "3.1.2"  # Spark version
  restartPolicy:
    type: OnFailure  # Restart policy
  driver:
    cores: 1
    coreLimit: "1200m"  # Driver core limits
    memory: "512m"  # Driver memory
  executor:
    cores: 1
    instances: 2
    memory: "512m"  # Executor memory
